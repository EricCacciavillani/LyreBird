{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "\n",
    "import shelve\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "import pretty_midi\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from Pre_Production.Midi_Pre_Processor import *\n",
    "from Pre_Production.Model_Generator import *\n",
    "from Shared_Files.Music_Pallete import *\n",
    "from Pre_Production.Model_Generator import *\n",
    "from Pre_Production.Music_Translation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found stored pre processor!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s, Guitar]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesizing wanted instr/note pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:40<00:00, 20.76s/it, Drums]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instr:Guitar Matrix_Shape: (529, 63063)\n",
      "instr:Piano Matrix_Shape: (584, 63063)\n",
      "instr:Brass Matrix_Shape: (456, 63063)\n",
      "instr:Synth Matrix_Shape: (1260, 63063)\n",
      "instr:Drums Matrix_Shape: (182, 63063)\n"
     ]
    }
   ],
   "source": [
    "pre_processor_obj = None\n",
    "pre_processor_shelve = shelve.open(ABS_PATHS.SHELVES_PATH\n",
    "                                   + SHELVE_NAMES.PRE_PROCESSOR)\n",
    "\n",
    "# Check to see if the object already exists\n",
    "if \"pre_processor\" in pre_processor_shelve.keys():\n",
    "    print(\"Found stored pre processor!\")\n",
    "    pre_processor_obj = pre_processor_shelve[\"pre_processor\"]\n",
    "\n",
    "# Pre-processor not found generate pre-processor\n",
    "else:\n",
    "\n",
    "    print(\"Generating pre processor!\")\n",
    "    pre_processor_obj = MidiPreProcessor(\n",
    "        ABS_PATHS.TRAINING_DATASET_DIRECTORY_PATH)\n",
    "\n",
    "    pre_processor_shelve[\"pre_processor\"] = pre_processor_obj\n",
    "\n",
    "pre_processor_shelve.close()\n",
    "\n",
    "instrument_name_contains = {\"Guitar\": False,\n",
    "                            \"Piano\": False,\n",
    "                            \"Brass\": False,\n",
    "                            \"Synth\": False,\n",
    "                            \"Drums\": True}\n",
    "\n",
    "all_instruments = pre_processor_obj.return_all_instruments()\n",
    "instr_note_pairs_dict = pre_processor_obj.return_instr_note_pairs_dict()\n",
    "\n",
    "\n",
    "print(\"Synthesizing wanted instr/note pairs...\")\n",
    "instr_wave_forms = get_instr_wave_forms(instrument_name_contains=instrument_name_contains,\n",
    "                                        all_instruments=all_instruments,\n",
    "                                        instr_note_pairs_dict=instr_note_pairs_dict,\n",
    "                                        unique_matrix=True)\n",
    "\n",
    "\n",
    "inst_waves_list = []\n",
    "for instr, waves in instr_wave_forms.items():\n",
    "    print(\"instr:{0} Matrix_Shape: {1}\".format(instr, waves.shape))\n",
    "    inst_waves_list.append(waves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "INSTRUMENTS_NUM = len(inst_waves_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def mulaw(x, MU):\n",
    "    return tf.sign(x) * tf.log(1. + MU * tf.abs(x)) / tf.log(1. + MU)\n",
    "\n",
    "def inv_mulaw(x, MU):\n",
    "    return tf.sign(x) * (1. / MU) * (tf.pow(1. + MU, tf.abs(x)) - 1.)\n",
    "    \n",
    "def naive_wavenet(inputs, condition, layers, h_filters, out_filters, name='naive_wavenet', reuse=False):\n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        \n",
    "        outputs = tf.pad(inputs, [[0, 0], [1, 0], [0, 0]])\n",
    "        outputs = tf.layers.conv1d(inputs=outputs, filters=h_filters, \n",
    "                                       kernel_size=2, dilation_rate=1, use_bias=False)\n",
    "        dilation_sum = 1\n",
    "        skips = []\n",
    "\n",
    "        for layer in range(layers):\n",
    "            dilation = 2 ** layer\n",
    "            dilation_sum += dilation\n",
    "            layer_outputs = tf.pad(outputs, [[0, 0], [dilation, 0], [0, 0]])\n",
    "            filter_outputs = tf.layers.conv1d(inputs=layer_outputs, filters=h_filters, \n",
    "                                       kernel_size=2, dilation_rate=dilation, use_bias=False)\n",
    "            gate_outputs = tf.layers.conv1d(inputs=layer_outputs, filters=h_filters, \n",
    "                                       kernel_size=2, dilation_rate=dilation, use_bias=False)\n",
    "            if condition is not None:\n",
    "                filter_condition = tf.layers.dense(condition, h_filters)\n",
    "                gate_condition = tf.layers.dense(condition, h_filters)\n",
    "            else:\n",
    "                filter_condition = 0\n",
    "                gate_condition = 0\n",
    "\n",
    "            layer_outputs = tf.nn.tanh(filter_outputs + filter_condition) * \\\n",
    "                            tf.nn.sigmoid(gate_outputs + gate_condition)\n",
    "\n",
    "            residual = tf.layers.dense(layer_outputs, h_filters)\n",
    "            outputs += residual\n",
    "\n",
    "            skip = tf.layers.dense(layer_outputs, h_filters)\n",
    "            skips.append(skip)\n",
    "\n",
    "        outputs = tf.nn.relu(sum(skips))\n",
    "        outputs = tf.layers.dense(outputs, out_filters, activation=tf.nn.relu)\n",
    "        outputs = tf.layers.dense(outputs, out_filters, activation=None)\n",
    "\n",
    "    return dilation_sum, outputs\n",
    "\n",
    "def downsample(inputs, pool_size, channel):\n",
    "    #pad_size = (pool_size - 1) - (tf.shape(inputs)[1] - pool_size + 1) % pool_size\n",
    "    #outputs = tf.pad(inputs, [[0, 0], [pad_size, 0], [0, 0]])\n",
    "    outputs = tf.layers.average_pooling1d(inputs=inputs, pool_size=pool_size, strides=pool_size)\n",
    "    #outputs = tf.reshape(outputs, [tf.shape(outputs)[0], tf.shape(outputs)[1], channel])\n",
    "    pad_size = 1\n",
    "    return pad_size, outputs\n",
    "\n",
    "def upsample(inputs, output_size, channel):\n",
    "    outputs = tf.expand_dims(inputs, axis=1)\n",
    "    outputs = tf.image.resize_nearest_neighbor(outputs, [1, output_size])\n",
    "    outputs = tf.squeeze(outputs, axis=1)\n",
    "    outputs = tf.reshape(outputs, [tf.shape(outputs)[0], tf.shape(outputs)[1], channel])\n",
    "    return outputs[:, -output_size:]\n",
    "\n",
    "def domain_confusion(inputs, layers, domain_num, h_filters):\n",
    "    outputs = inputs\n",
    "    for layer in range(layers):\n",
    "        dilation = 2 ** layers\n",
    "        outputs = tf.layers.conv1d(inputs=outputs, filters=h_filters, kernel_size=2, \n",
    "                                   dilation_rate=1, activation=tf.nn.elu)\n",
    "    \n",
    "    outputs = tf.layers.dense(outputs, domain_num, activation=tf.nn.tanh)\n",
    "    outputs = tf.layers.dense(outputs, domain_num)\n",
    "    return outputs\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "\n",
    "class FlipGradientBuilder(object):\n",
    "    def __init__(self):\n",
    "        self.num_calls = 0\n",
    "\n",
    "    def __call__(self, x, l=1.0):\n",
    "        grad_name = \"FlipGradient%d\" % self.num_calls\n",
    "        @ops.RegisterGradient(grad_name)\n",
    "        def _flip_gradients(op, grad):\n",
    "            return [tf.negative(grad) * l]\n",
    "        \n",
    "        g = tf.get_default_graph()\n",
    "        with g.gradient_override_map({\"Identity\": grad_name}):\n",
    "            y = tf.identity(x)\n",
    "            \n",
    "        self.num_calls += 1\n",
    "        return y\n",
    "    \n",
    "flip_gradient = FlipGradientBuilder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "MU = 256\n",
    "LATENT_DIM = 64\n",
    "POOL_SIZE = 400\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/eric/Desktop/LyreBird/Data_Dump/Saved_Models/LyreBird_TN/model.ckpt-119\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey wavenet_decoder_0/conv1d/kernel not found in checkpoint\n\t [[node save/RestoreV2 (defined at <ipython-input-9-68a9a7f35281>:120)  = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-68a9a7f35281>\", line 120, in <module>\n    saver = tf.train.Saver()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1102, in __init__\n    self.build()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1114, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1151, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 795, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 406, in _AddRestoreOps\n    restore_sequentially)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 862, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1466, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey wavenet_decoder_0/conv1d/kernel not found in checkpoint\n\t [[node save/RestoreV2 (defined at <ipython-input-9-68a9a7f35281>:120)  = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key wavenet_decoder_0/conv1d/kernel not found in checkpoint\n\t [[{{node save/RestoreV2}} = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1545\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1546\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1547\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key wavenet_decoder_0/conv1d/kernel not found in checkpoint\n\t [[node save/RestoreV2 (defined at <ipython-input-9-68a9a7f35281>:120)  = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-68a9a7f35281>\", line 120, in <module>\n    saver = tf.train.Saver()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1102, in __init__\n    self.build()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1114, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1151, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 795, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 406, in _AddRestoreOps\n    restore_sequentially)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 862, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1466, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Key wavenet_decoder_0/conv1d/kernel not found in checkpoint\n\t [[node save/RestoreV2 (defined at <ipython-input-9-68a9a7f35281>:120)  = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1555\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1556\u001b[0;31m         \u001b[0mnames_to_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_graph_key_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1557\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mobject_graph_key_mapping\u001b[0;34m(checkpoint_path)\u001b[0m\n\u001b[1;32m   1829\u001b[0m   object_graph_string = reader.get_tensor(\n\u001b[0;32m-> 1830\u001b[0;31m       checkpointable.OBJECT_GRAPH_PROTO_KEY)\n\u001b[0m\u001b[1;32m   1831\u001b[0m   object_graph_proto = (\n",
      "\u001b[0;32m~/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mget_tensor\u001b[0;34m(self, tensor_str)\u001b[0m\n\u001b[1;32m    370\u001b[0m         return CheckpointReader_GetTensor(self, compat.as_bytes(tensor_str),\n\u001b[0;32m--> 371\u001b[0;31m                                           status)\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-68a9a7f35281>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;31m# Restore variables from disk.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABS_PATHS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODELS_PATH_LYREBIRD_TN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/model.ckpt-\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m119\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model restored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1560\u001b[0m         \u001b[0;31m# a helpful message (b/110263146)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m         raise _wrap_restore_error_with_msg(\n\u001b[0;32m-> 1562\u001b[0;31m             err, \"a Variable name or other graph key that is missing\")\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m       \u001b[0;31m# This is an object-based checkpoint. We'll print a warning and then do\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey wavenet_decoder_0/conv1d/kernel not found in checkpoint\n\t [[node save/RestoreV2 (defined at <ipython-input-9-68a9a7f35281>:120)  = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-68a9a7f35281>\", line 120, in <module>\n    saver = tf.train.Saver()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1102, in __init__\n    self.build()\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1114, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1151, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 795, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 406, in _AddRestoreOps\n    restore_sequentially)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 862, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1466, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/eric/anaconda3/envs/LyreBird/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey wavenet_decoder_0/conv1d/kernel not found in checkpoint\n\t [[node save/RestoreV2 (defined at <ipython-input-9-68a9a7f35281>:120)  = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "'''\n",
    "\n",
    "INPUT LAYER\n",
    "\n",
    "'''\n",
    "# wave input\n",
    "x_holder = tf.placeholder(dtype=tf.float32, shape=[None, None])\n",
    "x_mulaw = mulaw(x_holder, MU)\n",
    "x_onehot_index = tf.clip_by_value(tf.cast((x_mulaw + 1.) * 0.5 * MU, tf.int32), 0, MU - 1)\n",
    "x_onehot = tf.one_hot(x_onehot_index, depth=MU)\n",
    "\n",
    "# label input\n",
    "label_holder = tf.placeholder(dtype=tf.int32, shape=())\n",
    "\n",
    "'''\n",
    "\n",
    "ENCODER LAYER\n",
    "\n",
    "'''\n",
    "\n",
    "# encode\n",
    "_, latents = naive_wavenet(inputs=tf.expand_dims(x_holder, axis=-1), condition=None, \n",
    "                           layers=9, h_filters=64, out_filters=LATENT_DIM, name='wavenet_encoder')\n",
    "\n",
    "# downsample\n",
    "_, down_latents = downsample(latents, POOL_SIZE, LATENT_DIM)\n",
    "\n",
    "# upsample\n",
    "up_latents = upsample(down_latents, tf.shape(x_holder)[1], LATENT_DIM)\n",
    "\n",
    "'''\n",
    "\n",
    "DOMAIN CONFUSION LAYER\n",
    "\n",
    "'''\n",
    "\n",
    "# gradient reversal layer\n",
    "flipped_down_latents = flip_gradient(down_latents)\n",
    "#flipped_down_latents = down_latents\n",
    "\n",
    "# domain predict\n",
    "label_predicts = domain_confusion(flipped_down_latents, 3, INSTRUMENTS_NUM, 128)\n",
    "label_predicts = tf.reduce_mean(label_predicts, axis=1)\n",
    "label_predicts_prob = tf.nn.softmax(label_predicts)\n",
    "label_tiled = tf.tile(tf.expand_dims(label_holder, axis=0), [tf.shape(label_predicts)[0]])\n",
    "\n",
    "# loss\n",
    "domain_confusion_loss = tf.losses.sparse_softmax_cross_entropy(labels=label_tiled, logits=label_predicts)\n",
    "\n",
    "'''\n",
    "\n",
    "DECODER LAYER for traininng\n",
    "\n",
    "'''\n",
    "decode_losses = []\n",
    "samples_list = []\n",
    "for instrument_index in range(INSTRUMENTS_NUM):\n",
    "    # decode\n",
    "    dilation_sum, outputs = naive_wavenet(inputs=x_onehot, condition=up_latents, \n",
    "                                          layers=9, h_filters=64, out_filters=MU, \n",
    "                                          name='wavenet_decoder_' + str(instrument_index))\n",
    "    outputs_probs = tf.nn.softmax(outputs)\n",
    "    \n",
    "    # sample from outputs\n",
    "    dist = tf.distributions.Categorical(probs=outputs_probs)\n",
    "    samples = inv_mulaw(tf.cast(dist.sample(), tf.float32) / MU * 2. - 1., MU)\n",
    "    samples_list.append(samples)\n",
    "\n",
    "    # loss\n",
    "    decode_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=x_onehot_index[:, dilation_sum + 1:],\n",
    "                                                                 logits=outputs[:, dilation_sum:-1])\n",
    "    decode_loss = tf.reduce_mean(decode_loss)\n",
    "    decode_losses.append(decode_loss)\n",
    "\n",
    "decode_losses = tf.stack(decode_losses, axis=0) * tf.one_hot(label_holder, depth=INSTRUMENTS_NUM)\n",
    "decode_losses = tf.reduce_mean(decode_losses)\n",
    "\n",
    "loss = decode_losses + 1e-2 * domain_confusion_loss\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "\n",
    "'''\n",
    "\n",
    "DECODER LAYER for inference\n",
    "\n",
    "'''\n",
    "\n",
    "# input for decoder\n",
    "latents_holder = tf.placeholder(dtype=tf.float32, shape=[None, None, LATENT_DIM])\n",
    "\n",
    "inference_sample_list = []\n",
    "\n",
    "for instrument_index in range(INSTRUMENTS_NUM):\n",
    "    # decode\n",
    "    _, outputs = naive_wavenet(inputs=x_onehot, condition=latents_holder, \n",
    "                               layers=9, h_filters=64, out_filters=MU, \n",
    "                               name='wavenet_decoder_' + str(instrument_index), reuse=True)\n",
    "    outputs_probs = tf.nn.softmax(outputs)\n",
    "\n",
    "    # sample from outputs\n",
    "    dist = tf.distributions.Categorical(probs=outputs_probs[:, -1])\n",
    "    sample = inv_mulaw(tf.cast(dist.sample(), tf.float32) / MU * 2. - 1., MU)\n",
    "    inference_sample_list.append(sample)\n",
    "\n",
    "'''\n",
    "\n",
    "SESSION CREATE\n",
    "\n",
    "'''\n",
    "\n",
    "config = tf.ConfigProto(\n",
    "        device_count = {'GPU': 0}\n",
    "    )\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "#sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "# Restore variables from disk.\n",
    "saver.restore(sess, ABS_PATHS.SAVED_MODELS_PATH_LYREBIRD_TN + \"/model.ckpt-\" + str(115))\n",
    "print(\"Model restored.\")\n",
    "\n",
    "print('Tensorflow graph created.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch_shift(inputs, start_index, end_index, n_steps):\n",
    "    shifted = librosa.effects.pitch_shift(inputs[start_index:end_index], 8000, n_steps)\n",
    "    outputs = np.concatenate([inputs[:start_index], shifted, inputs[end_index:]], axis=0)\n",
    "    return outputs\n",
    "\n",
    "def wave_augmentation(inputs):\n",
    "    length = np.random.randint(2000, 4000, 1)[0]\n",
    "    start_index = np.random.randint(0, len(inputs) - length, 1)[0]\n",
    "    end_index = start_index + length\n",
    "    n_steps = float(np.random.ranf(1)[0] - 0.5)\n",
    "    return pitch_shift(inputs, start_index, end_index, n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "while(True):\n",
    "    for i in range(1):\n",
    "        for instrument_index in range(INSTRUMENTS_NUM):\n",
    "            batch_size = 3\n",
    "            indexes = np.random.randint(0, inst_waves_list[instrument_index].shape[0], batch_size)\n",
    "            augmented = []\n",
    "            for _wave in inst_waves_list[instrument_index][indexes]:\n",
    "                augmented.append(wave_augmentation(_wave))\n",
    "            augmented = np.stack(augmented, axis=0)\n",
    "            _, _loss = sess.run([train_step, loss], feed_dict={x_holder: augmented,\n",
    "                                                     label_holder: instrument_index})\n",
    "            print(i, _loss)\n",
    "        \n",
    "    clear_output()\n",
    "    \n",
    "    inst_waves_test = []\n",
    "    for instrument_index in range(INSTRUMENTS_NUM):\n",
    "        index = np.random.randint(0, inst_waves_list[instrument_index].shape[0], 1)\n",
    "        inst_waves_test.append(inst_waves_list[instrument_index][index])\n",
    "    \n",
    "    inst_waves_test = np.vstack(inst_waves_test)\n",
    "    _down_latents, _label_predicts_prob, _samples_list = sess.run([down_latents, label_predicts_prob, samples_list], \n",
    "                                                   feed_dict={x_holder: inst_waves_test})\n",
    "    \n",
    "    for instrument_index1 in range(INSTRUMENTS_NUM):\n",
    "        for instrument_index2 in range(INSTRUMENTS_NUM):\n",
    "            plt.figure(figsize=[18, 3])\n",
    "            plt.plot(inst_waves_test[instrument_index1], alpha=0.5)\n",
    "            plt.plot(_samples_list[instrument_index1][instrument_index2], alpha=0.5)\n",
    "            plt.ylim([-1., 1.])\n",
    "            plt.show()\n",
    "    \n",
    "    for _down_latent, inst_waves_test1 in zip(_down_latents, inst_waves_test):\n",
    "        plt.figure(figsize=[18, 3])\n",
    "        plt.plot(inst_waves_test1)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=[18, 3])\n",
    "        plt.plot(_down_latent)\n",
    "        plt.show()\n",
    "        \n",
    "    plt.figure(figsize=[18, 3])\n",
    "    plt.plot(_label_predicts_prob[0, :])\n",
    "    plt.ylim([0., 1.])\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_instrument_index = 2\n",
    "dest_instrument_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.randint(0, inst_waves_list[src_instrument_index].shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_src = inst_waves_list[src_instrument_index][index]\n",
    "\n",
    "_latents = sess.run(up_latents, feed_dict={x_holder: _src})\n",
    "\n",
    "print(_latents.shape)\n",
    "\n",
    "plt.figure(figsize=[18, 2])\n",
    "plt.plot(_src[0])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=[18, 2])\n",
    "plt.plot(_latents[0])\n",
    "plt.show()\n",
    "\n",
    "import IPython.display as ipd\n",
    "ipd.Audio(_src[0], rate=8000) # load a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "_samples = np.zeros([1, 1024])\n",
    "_latents = np.concatenate([np.zeros([1, 1024, LATENT_DIM]), _latents], axis=1)\n",
    "for i in tqdm(range(T)):\n",
    "    _inference_sample_list = sess.run(inference_sample_list, feed_dict={x_holder: _samples[:, -1024:], \n",
    "                                                                        latents_holder: _latents[:, i:i + 1024]})\n",
    "    _samples = np.concatenate([_samples, np.expand_dims(_inference_sample_list[dest_instrument_index], axis=0)], axis=-1)\n",
    "    if i % 200 == 0:\n",
    "        clear_output()\n",
    "        plt.plot(_src[0, :i])\n",
    "        plt.show()\n",
    "        \n",
    "        plt.plot(_samples[0, 1024:])\n",
    "        plt.show()\n",
    "\n",
    "print(_samples.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Audio(_src[0], rate=8000) # load a NumPy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(_samples[0], rate=8000) # load a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
